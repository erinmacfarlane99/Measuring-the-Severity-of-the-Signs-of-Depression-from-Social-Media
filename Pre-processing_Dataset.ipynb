{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pre-processing_Dataset.ipynb","provenance":[],"mount_file_id":"1J8XAD7JPShZQuBRJ6zfFjV1dUtH4y858","authorship_tag":"ABX9TyP6W3qf3dOfEGG8aZmP45yn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"sVqe71-PJJ4A"},"source":["# **Exploring and Preparing Dataset**\n","This notebook explores and processes the dataset provided by CLEF for Task 3 of CLEF's eRisk 2021 workshop: https://early.irlab.org."]},{"cell_type":"markdown","metadata":{"id":"HIRXF6ihRWN6"},"source":["### **Importing and Installing Required Libraries**\n","\n","I have added all the required data for my project to my Google Drive in the directory 'CS408', making it easy to navigate and access data using shell commands.\n","\n","\n","\n","*   %pwd - print working directory\n","*   %cd filepath - change directory\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0xh1ZlzRYjg","executionInfo":{"status":"ok","timestamp":1629035049507,"user_tz":-60,"elapsed":206,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"117fe4d0-0e60-4017-fd3e-c23a2177045e"},"source":["import pandas as pd\n","import csv, glob, os\n","from xml.dom import minidom\n","\n","%cd drive/MyDrive/CS408/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/MyDrive/CS408/'\n","/content/drive/MyDrive/CS408\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TClFDv31Kros"},"source":["### **Indexing Beck's Depression Inventory (BDI)**\n","\n","For this task, subjects have provided their Reddit history for CLEF's task alongside their answers to Beck's Depression Inventory (BDI). BDI is a 21-item, self-reported questionnaire that is used to estimate the severity of someone's depression. \n","\n","The aim of the systems are to accurately predict a user's answers to BDI, given their Reddit history.\n","\n","In order to easily locate and use data from BDI, I have created a csv containing all the questions and possible answers. This csv has 4 columns:\n","\n","\n","*   **Question Number:** position of question in BDI (1-21)\n","*   **Question:** the name of the question statement (i.e. 'Sadness', 'Agitation' etc)\n","*   **Class:** answer value (0-3 possible values)\n","  * For questions 16 and 18 (Changes in Sleeping Pattern and Changes in Appetite) there are 6 possible answer values: 0, 1a, 1b, 2a, 2b, 3a, 3b\n","*   **Answer:** written statement corresponding to the answer value"]},{"cell_type":"code","metadata":{"id":"lYMhIzWK90Le"},"source":["bdi_questions_answers = pd.read_csv(\"BDI_csv.csv\")\n","\n","#list of all 21 question names in BDI i.e. ['Sadness', 'Pessimism', ...]\n","questions = bdi_questions_answers['Question'].unique()\n","\n","#list of lists where element contains all possible answers per question \n","answers = []\n","\n","#look up in bdi_questions_answers df for all possible answers per question and add to answers\n","for question_name in questions:\n","  answers.append(bdi_questions_answers.loc[((bdi_questions_answers['Question'] == question_name)), 'Answer'].values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"cM3iAtCCDY7J","executionInfo":{"status":"ok","timestamp":1629035010049,"user_tz":-60,"elapsed":189,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"514cd8a8-2730-44c1-a49f-18ee7d90e328"},"source":["bdi_questions_answers.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Question Number</th>\n","      <th>Question</th>\n","      <th>Class</th>\n","      <th>Answer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Sadness</td>\n","      <td>0</td>\n","      <td>I do not feel sad.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Sadness</td>\n","      <td>1</td>\n","      <td>I feel sad much of the time.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Sadness</td>\n","      <td>2</td>\n","      <td>I am sad all the time.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>Sadness</td>\n","      <td>3</td>\n","      <td>I am so sad or unhappy that I can't stand it.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2</td>\n","      <td>Pessimism</td>\n","      <td>0</td>\n","      <td>I am not discouraged about my future.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Question Number  ...                                         Answer\n","0                1  ...                             I do not feel sad.\n","1                1  ...                   I feel sad much of the time.\n","2                1  ...                         I am sad all the time.\n","3                1  ...  I am so sad or unhappy that I can't stand it.\n","4                2  ...          I am not discouraged about my future.\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"oJzk00CjFvm2"},"source":["## **Wrangling CLEF dataset**\n","\n","The dataset provided by CLEF includes:\n","*   **90 XML Files:** each subject has a XML file which includes all of their Reddit posts\n","*   **Space delimited TXT file for 2019 & 2020:** each year a txt file containing all subjects and their answers to BDI is created\n","\n","I have taken this data and created a csv for each question in Beck's Depression Inventory (BDI) which contains all of the subject's Reddit posts alongside their answer to this question. \n","\n","The csvs created for each question have 4 columns:\n","\n","*   **Subject:** subject name\n","*   **Class:** the answer value chosen by subject \n","*   **Answer:** the corresponding answer statement \n","*   **Post:** one of the subject's Reddit posts\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3WCTZ87ZCEvP","executionInfo":{"status":"ok","timestamp":1623059661839,"user_tz":-60,"elapsed":11,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"9c3e7f42-50f9-4bd9-e728-3e62ed8c038b"},"source":["%cd question_csvs/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/CS408/question_csvs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"E0j_XcnP_rzg"},"source":["index = 0\n","for question in questions:\n","  index += 1\n","  #Create csv per question with all subjects posts along with their answer value to question\n","  newfile = \"answer_classes_posts_\" + question + \".csv\"\n","  with open(newfile, mode='w') as csv_file:\n","      csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","      #Add the column headers\n","      csv_writer.writerow(['Subject', 'Class', 'Answer', 'Post'])\n","      folder_path = '/content/drive/MyDrive/CS408/2019_2020_TEST_DATA/'\n","      allitems = []\n","      answer = ''\n","\n","      #loop through all subject xml files\n","      for filename in glob.glob(os.path.join(folder_path, '*.xml')):\n","        #Get all posts per user\n","        with open(filename, 'r') as f:\n","\n","          #Clear allitems per user so there's no duplicate posts\n","          allitems = []\n","\n","          #Parse xml file for only the TEXT elements (the posts)\n","          mydoc = minidom.parse(filename)\n","          items = mydoc.getElementsByTagName('TEXT')\n","          allitems = allitems + items\n","\n","          #Get subjectname\n","          base = (os.path.basename(filename))\n","          subjectname = os.path.splitext(base)[0]\n","\n","          #Search 2019/2020 txt files for subjectname\n","          for txtname in glob.glob(os.path.join(folder_path, '*.txt')):\n","            with open(txtname, 'r') as txt:\n","              for line in txt:\n","                values = line.split()\n","                if (values[0] == subjectname):\n","                  for i in allitems:\n","                    post = i.firstChild.data\n","                    #Check post isn't empty then add post to csv\n","                    if post != \"  \":\n","                      answer = bdi_questions_answers.loc[((bdi_questions_answers['Question'] == question) & (bdi_questions_answers['Class'] == values[index])), 'Answer']\n","                      csv_writer.writerow([subjectname, values[index], answer.values[0], post])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fZjoky1xDocc","executionInfo":{"status":"ok","timestamp":1629035126487,"user_tz":-60,"elapsed":894,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}}},"source":["sadness_df = pd.read_csv(\"answer_classes_posts_Sadness.csv\") "],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":419},"id":"oH0ze4TzD2vV","executionInfo":{"status":"ok","timestamp":1629035135075,"user_tz":-60,"elapsed":204,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"1e600fef-e8ad-4d29-fe58-45e6121488d3"},"source":["sadness_df"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Class</th>\n","      <th>Answer</th>\n","      <th>Post</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>subject5897</td>\n","      <td>2</td>\n","      <td>I am sad all the time.</td>\n","      <td>I didnt drop out, but took some time off afte...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>subject5897</td>\n","      <td>2</td>\n","      <td>I am sad all the time.</td>\n","      <td>Definitely doable, just be prepared for lots ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>subject5897</td>\n","      <td>2</td>\n","      <td>I am sad all the time.</td>\n","      <td>You definitely should!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>subject5897</td>\n","      <td>2</td>\n","      <td>I am sad all the time.</td>\n","      <td>Wow I love this, do you have a website?</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>subject5897</td>\n","      <td>2</td>\n","      <td>I am sad all the time.</td>\n","      <td>Watermelon snow!</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>43759</th>\n","      <td>subject97982</td>\n","      <td>3</td>\n","      <td>I am so sad or unhappy that I can't stand it.</td>\n","      <td>Added\\n</td>\n","    </tr>\n","    <tr>\n","      <th>43760</th>\n","      <td>subject97982</td>\n","      <td>3</td>\n","      <td>I am so sad or unhappy that I can't stand it.</td>\n","      <td>i keep going offline to add more friends i ha...</td>\n","    </tr>\n","    <tr>\n","      <th>43761</th>\n","      <td>subject97982</td>\n","      <td>3</td>\n","      <td>I am so sad or unhappy that I can't stand it.</td>\n","      <td>and Slugma has flame body for breeding =D</td>\n","    </tr>\n","    <tr>\n","      <th>43762</th>\n","      <td>subject97982</td>\n","      <td>3</td>\n","      <td>I am so sad or unhappy that I can't stand it.</td>\n","      <td>certainly\\n</td>\n","    </tr>\n","    <tr>\n","      <th>43763</th>\n","      <td>subject97982</td>\n","      <td>3</td>\n","      <td>I am so sad or unhappy that I can't stand it.</td>\n","      <td>Added</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>43764 rows Ã— 4 columns</p>\n","</div>"],"text/plain":["            Subject  ...                                               Post\n","0       subject5897  ...   I didnt drop out, but took some time off afte...\n","1       subject5897  ...   Definitely doable, just be prepared for lots ...\n","2       subject5897  ...                           You definitely should!  \n","3       subject5897  ...          Wow I love this, do you have a website?  \n","4       subject5897  ...                                 Watermelon snow!  \n","...             ...  ...                                                ...\n","43759  subject97982  ...                                           Added\\n \n","43760  subject97982  ...   i keep going offline to add more friends i ha...\n","43761  subject97982  ...         and Slugma has flame body for breeding =D \n","43762  subject97982  ...                                       certainly\\n \n","43763  subject97982  ...                                             Added \n","\n","[43764 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":13}]}]}