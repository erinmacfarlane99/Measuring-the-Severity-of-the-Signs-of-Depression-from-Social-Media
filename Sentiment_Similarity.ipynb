{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sentiment_Similarity.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1OovMCnod_dI9XbssBBR89W0gM9tZp_Qb","authorship_tag":"ABX9TyMqnKTXG/pNvtWaGLOXIc6m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"h7scG9hnXF5j"},"source":["# **Sentiment Similarity System**\n","This system compares the sentiment between all of a user's Reddit postings and the answers to a question in BDI. In order to pick an answer for a question, each answer to BDI is scored and then the subjects posts are scored. Each post is classified based on which answer it's sentiment score is closest to. The answer classes that have been picked the most, for all the posts, is then chosen for that question.\n","\n","The system tests different sentiment scorers to analyse which one performs best at the task."]},{"cell_type":"markdown","metadata":{"id":"UROnhjtWECXb"},"source":["# **Environment Set-up**"]},{"cell_type":"markdown","metadata":{"id":"XGP3xGPyECSn"},"source":["### **Importing and Installing Required Libraries**"]},{"cell_type":"code","metadata":{"id":"NJoU757ID0gZ","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1629107114391,"user_tz":-60,"elapsed":121976,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"ad98cfac-fd2c-4e23-9a2c-64aea4f4d6c0"},"source":["#libraries utilised to parse and index dataset\n","import os, sys, glob, csv\n","import numpy as np\n","import pandas as pd\n","\n","from xml.dom import minidom\n","\n","#Google Colab does not have awessome installed as default so pip install is required\n","!pip install awessome\n","import awessome\n","from awessome.awessome_builder import *"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting awessome\n","  Downloading awessome-0.0.14-py2.py3-none-any.whl (34 kB)\n","Collecting certifi==2020.6.20\n","  Downloading certifi-2020.6.20-py2.py3-none-any.whl (156 kB)\n","\u001b[K     |████████████████████████████████| 156 kB 18.9 MB/s \n","\u001b[?25hCollecting numpy==1.19.2\n","  Downloading numpy-1.19.2-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n","\u001b[K     |████████████████████████████████| 14.5 MB 60.7 MB/s \n","\u001b[?25hCollecting sentence-transformers==0.3.8\n","  Downloading sentence-transformers-0.3.8.tar.gz (66 kB)\n","\u001b[K     |████████████████████████████████| 66 kB 5.8 MB/s \n","\u001b[?25hCollecting nltk==3.5\n","  Downloading nltk-3.5.zip (1.4 MB)\n","\u001b[K     |████████████████████████████████| 1.4 MB 74.7 MB/s \n","\u001b[?25hCollecting tokenizers==0.8.1rc2\n","  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","\u001b[K     |████████████████████████████████| 3.0 MB 70.6 MB/s \n","\u001b[?25hRequirement already satisfied: chardet==3.0.4 in /usr/local/lib/python3.7/dist-packages (from awessome) (3.0.4)\n","Collecting scipy==1.5.3\n","  Downloading scipy-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n","\u001b[K     |████████████████████████████████| 25.9 MB 1.3 MB/s \n","\u001b[?25hRequirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from awessome) (1.15.0)\n","Collecting scikit-learn==0.23.2\n","  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n","\u001b[K     |████████████████████████████████| 6.8 MB 83.8 MB/s \n","\u001b[?25hCollecting urllib3==1.25.11\n","  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n","\u001b[K     |████████████████████████████████| 127 kB 97.7 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from awessome) (3.7.4.3)\n","Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from awessome) (2.4.7)\n","Collecting sentencepiece==0.1.94\n","  Downloading sentencepiece-0.1.94-cp37-cp37m-manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 72.0 MB/s \n","\u001b[?25hRequirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from awessome) (2.10)\n","Collecting sacremoses==0.0.43\n","  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n","\u001b[K     |████████████████████████████████| 883 kB 85.3 MB/s \n","\u001b[?25hCollecting joblib==0.17.0\n","  Downloading joblib-0.17.0-py3-none-any.whl (301 kB)\n","\u001b[K     |████████████████████████████████| 301 kB 79.1 MB/s \n","\u001b[?25hCollecting regex==2020.10.23\n","  Downloading regex-2020.10.23-cp37-cp37m-manylinux2010_x86_64.whl (662 kB)\n","\u001b[K     |████████████████████████████████| 662 kB 72.7 MB/s \n","\u001b[?25hCollecting threadpoolctl==2.1.0\n","  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n","Collecting dataclasses==0.6\n","  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n","Collecting packaging==20.4\n","  Downloading packaging-20.4-py2.py3-none-any.whl (37 kB)\n","Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from awessome) (3.0.12)\n","Collecting torch==1.7.0\n","  Downloading torch-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (776.7 MB)\n","\u001b[K     |████████████████████████████████| 776.7 MB 4.1 kB/s \n","\u001b[?25hCollecting transformers==3.3.1\n","  Downloading transformers-3.3.1-py3-none-any.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 82.9 MB/s \n","\u001b[?25hCollecting future==0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 69.8 MB/s \n","\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from awessome) (7.1.2)\n","Collecting tqdm==4.51.0\n","  Downloading tqdm-4.51.0-py2.py3-none-any.whl (70 kB)\n","\u001b[K     |████████████████████████████████| 70 kB 9.8 MB/s \n","\u001b[?25hCollecting requests==2.24.0\n","  Downloading requests-2.24.0-py2.py3-none-any.whl (61 kB)\n","\u001b[K     |████████████████████████████████| 61 kB 462 kB/s \n","\u001b[?25hBuilding wheels for collected packages: future, nltk, sacremoses, sentence-transformers\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=463ab1056925f6c06a1cea93da1f426f0162c6705bc6e0fa75063bfaaaa3c4c2\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434692 sha256=5d0711fb0b97b2264aeb790cf51fb151bdd0669066896e27abbaccdfbd56638b\n","  Stored in directory: /root/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893250 sha256=9c40555237b4c524f0112fb978a082c3e5f8dd6dfd8b3c847610c4783759d301\n","  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n","  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sentence-transformers: filename=sentence_transformers-0.3.8-py3-none-any.whl size=101995 sha256=c96d49dafe50c983a3e83293e3dfd769aede8b61540247dfafac9bed4fbc1f0c\n","  Stored in directory: /root/.cache/pip/wheels/1c/43/65/fe0f3ea9327623e749a79eb5dfad85a809c84064b1cc4682c1\n","Successfully built future nltk sacremoses sentence-transformers\n","Installing collected packages: urllib3, tqdm, regex, numpy, joblib, certifi, tokenizers, threadpoolctl, sentencepiece, scipy, sacremoses, requests, packaging, future, dataclasses, transformers, torch, scikit-learn, nltk, sentence-transformers, awessome\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","  Attempting uninstall: tqdm\n","    Found existing installation: tqdm 4.62.0\n","    Uninstalling tqdm-4.62.0:\n","      Successfully uninstalled tqdm-4.62.0\n","  Attempting uninstall: regex\n","    Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Attempting uninstall: joblib\n","    Found existing installation: joblib 1.0.1\n","    Uninstalling joblib-1.0.1:\n","      Successfully uninstalled joblib-1.0.1\n","  Attempting uninstall: certifi\n","    Found existing installation: certifi 2021.5.30\n","    Uninstalling certifi-2021.5.30:\n","      Successfully uninstalled certifi-2021.5.30\n","  Attempting uninstall: scipy\n","    Found existing installation: scipy 1.4.1\n","    Uninstalling scipy-1.4.1:\n","      Successfully uninstalled scipy-1.4.1\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.0\n","    Uninstalling packaging-21.0:\n","      Successfully uninstalled packaging-21.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Attempting uninstall: nltk\n","    Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.7.0 which is incompatible.\n","torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.7.0 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.24.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n","albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Successfully installed awessome-0.0.14 certifi-2020.6.20 dataclasses-0.6 future-0.18.2 joblib-0.17.0 nltk-3.5 numpy-1.19.2 packaging-20.4 regex-2020.10.23 requests-2.24.0 sacremoses-0.0.43 scikit-learn-0.23.2 scipy-1.5.3 sentence-transformers-0.3.8 sentencepiece-0.1.94 threadpoolctl-2.1.0 tokenizers-0.8.1rc2 torch-1.7.0 tqdm-4.51.0 transformers-3.3.1 urllib3-1.25.11\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0xkXbl8rFvHD","executionInfo":{"status":"ok","timestamp":1629107114392,"user_tz":-60,"elapsed":5,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"ef0aecb0-3806-474d-9846-933bd27df638"},"source":["#change to correct directory\n","%cd drive/MyDrive/CS408/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/CS408\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"s98n3NW7J0-u"},"source":["# **Preparing Data**\n","\n","The dataset has been preprocessed here: https://colab.research.google.com/drive/1J8XAD7JPShZQuBRJ6zfFjV1dUtH4y858?usp=sharing"]},{"cell_type":"code","metadata":{"id":"uIdzJTG_FSSv"},"source":["bdi_questions_answers = pd.read_csv(\"BDI_csv.csv\")\n","\n","#list of all 21 question names in BDI i.e. ['Sadness', 'Pessimism', ...]\n","questions = bdi_questions_answers['Question'].unique()\n","\n","#list of lists where element contains all possible answers per question \n","answers = []\n","\n","#look up in bdi_questions_answers df for all possible answers per question and add to answers\n","for question_name in questions:\n","  answers.append(bdi_questions_answers.loc[((bdi_questions_answers['Question'] == question_name)), 'Answer'].values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ylf8CUhQeqjk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629107307309,"user_tz":-60,"elapsed":29706,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"bf1213ab-4ddd-450b-ad86-172dfc192c55"},"source":["%cd ../../question_csvs\n","#Creating data frames for each question \n","agitation_df = pd.read_csv(\"answer_classes_posts_Agitation.csv\") \n","appetite_df = pd.read_csv(\"answer_classes_posts_Changes in Appetite.csv\")\n","sleep_df = pd.read_csv(\"answer_classes_posts_Changes in Sleeping Pattern.csv\") \n","concentration_df = pd.read_csv(\"answer_classes_posts_Concentration Difficulty.csv\") \n","crying_df = pd.read_csv(\"answer_classes_posts_Crying.csv\") \n","guilty_df = pd.read_csv(\"answer_classes_posts_Guilty Feelings.csv\")\n","indecisive_df = pd.read_csv(\"answer_classes_posts_Indecisiveness.csv\") \n","irritability_df = pd.read_csv(\"answer_classes_posts_Irritability.csv\") \n","energy_df = pd.read_csv(\"answer_classes_posts_Loss of Energy.csv\") \n","sexinterest_df = pd.read_csv(\"answer_classes_posts_Loss of Interest in Sex.csv\") \n","interest_df = pd.read_csv(\"answer_classes_posts_Loss of Interest.csv\") \n","pleasure_df = pd.read_csv(\"answer_classes_posts_Loss of Pleasure.csv\") \n","pastfailure_df = pd.read_csv(\"answer_classes_posts_Past Failure.csv\") \n","pessimism_df = pd.read_csv(\"answer_classes_posts_Pessimism.csv\") \n","punishment_df = pd.read_csv(\"answer_classes_posts_Punishment Feelings.csv\") \n","sadness_df = pd.read_csv(\"answer_classes_posts_Sadness.csv\") \n","selfcritcalness_df = pd.read_csv(\"answer_classes_posts_Self-Criticalness.csv\") \n","selfdislike_df = pd.read_csv(\"answer_classes_posts_Self-Dislike.csv\") \n","suicidal_df = pd.read_csv(\"answer_classes_posts_Suicidal Thoughts or Wishes.csv\") \n","fatigue_df = pd.read_csv(\"answer_classes_posts_Tiredness or Fatigue.csv\") \n","worthlessness_df = pd.read_csv(\"answer_classes_posts_Worthlessness.csv\") \n","\n","#Create a list of the subject names as strings \n","# (any df could be used for this)\n","subjects = agitation_df['Subject'].unique()\n","\n","#Add all dataframes in order of BDI questions \n","BDI_df = [sadness_df, pessimism_df, pastfailure_df, pleasure_df, guilty_df, punishment_df, selfdislike_df, selfcritcalness_df, suicidal_df, crying_df, agitation_df, interest_df, indecisive_df, worthlessness_df, energy_df, sleep_df, irritability_df, appetite_df, concentration_df, fatigue_df, sexinterest_df]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/CS408/question_csvs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zuMQALTzE2zW"},"source":["# **Creating Sentiment Intensity Scorers**\n","In order to calculate a sentiment score for the BDI answers and for user's postings I am using the AWESSOME (A Word Embedding Sentiment Scorer Of Many Emotions) framework. This framework allows you to create your own sentiment intensity scorers and gives you freedom to adapt several parameters to fit your purpose.\n","\n","Details and implementations of the AWESSOME framework can be found here: https://github.com/cumulative-revelations/awessome.git."]},{"cell_type":"markdown","metadata":{"id":"kxluGYedkN9y"},"source":["### **BERT Sentiment Scorers**"]},{"cell_type":"code","metadata":{"id":"G4Nnv_JeE9w-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1628990147164,"user_tz":-60,"elapsed":20453,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"6ac0f9ea-3326-4788-a684-4b03040e04f1"},"source":["avg_bert_builder = SentimentIntensityScorerBuilder('avg', 'bert-base-nli-mean-tokens', 'cosine', '600', True)\n","bert_vader_avg_scorer = avg_bert_builder.build_scorer_from_prebuilt_lexicon('vader')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 405M/405M [00:07<00:00, 53.4MB/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"V5UtVhzxjsde"},"source":["max_bert_builder = SentimentIntensityScorerBuilder('max', 'bert-base-nli-mean-tokens', 'cosine', '600', True)\n","bert_vader_max_scorer = max_bert_builder.build_scorer_from_prebuilt_lexicon('vader')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k_jpz_w8mYBi"},"source":["### **DistilBERT Scorer**"]},{"cell_type":"code","metadata":{"id":"BV8NzXV1LPXr"},"source":["avg_distil_builder = SentimentIntensityScorerBuilder('avg', 'distilbert-base-nli-stsb-mean-tokens', 'cosine', '600', True)\n","distil_vader_avg_scorer = avg_distil_builder.build_scorer_from_prebuilt_lexicon('vader')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MGtt7u-UmZ3K"},"source":["### **RoBERTa Scorer**"]},{"cell_type":"code","metadata":{"id":"qWvR35bcpeM9"},"source":["avg_roberta_builder = SentimentIntensityScorerBuilder('avg', 'roberta-base-nli-stsb-mean-tokens', 'cosine', '600', True)\n","roberta_vader_avg_scorer = avg_roberta_builder.build_scorer_from_prebuilt_lexicon('vader')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hrOWjf_IEqSV"},"source":["# **Computing Sentiment Scores for BDI Answers**\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YkNlk98NqCNC","executionInfo":{"status":"ok","timestamp":1628990147165,"user_tz":-60,"elapsed":56,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"58fcbc46-ff6f-45c2-d5e2-26e911ad1fdb"},"source":["%cd Sentiment_Analysis/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/CS408/Sentiment_Analysis\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BSxef56TuBQ4"},"source":["**Calculates a sentiment score for the answers to BDI, using the chosen Sentiment Intensity Scorer**\n","\n","\n","*   scorer_name (*string*): name of scorer to name file\n","*   scorer (*SentimentIntensityScorer*): chosen sentiment scorer\n","\n"]},{"cell_type":"code","metadata":{"id":"xhA27VQPnAPb"},"source":["def score_BDI(scorer_name, scorer):\n","  #create csv file for the BDI answer sentiment scores \n","  filename = scorer_name + \"/BDI_sentiment.csv\"\n","  with open(filename, mode='w') as csv_file:\n","    csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","\n","    #add the column headers\n","    csv_writer.writerow(['Question', 'Answer', 'Sentiment'])\n","\n","    #calculate sentiment score for each answer per question\n","    for i, answer in enumerate(answers):\n","      for a in answer:\n","        csv_writer.writerow([questions[i], a, scorer.score_sentence(a)]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHbz09I1sqAu"},"source":["#example of input parameters for score_BDI function\n","score_BDI('distil_vader_avg_scorer', distil_vader_avg_scorer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cP3aUT1ruhJy"},"source":["# **Computing Sentiment Scores for Reddit Posts**"]},{"cell_type":"markdown","metadata":{"id":"44WH2jKrGXUV"},"source":["**Calculates a sentiment score for all of the Reddit posts, using the chosen Sentiment Intensity Scorer**\n","\n","*   scorer (*SentimentIntensityScorer*): chosen sentiment scorer\n","*   folder_path (*string*): path to data folder\n","\n"]},{"cell_type":"code","metadata":{"id":"LX9yrRWhGbuo"},"source":["def calc_sentiment(scorer):\n","  #loop through all subject xml files\n","  folder_path = '/content/drive/MyDrive/CS408/2019_2020_TEST_DATA/'\n","  for filename in glob.glob(os.path.join(folder_path, '*.xml')):\n","    #Get all posts per user\n","    with open(filename, 'r') as f:\n","\n","      #Get subjectname\n","      base = (os.path.basename(filename))\n","      subjectname = os.path.splitext(base)[0]\n","\n","      #Parse xml file for only the TEXT elements (the posts)\n","      mydoc = minidom.parse(filename)\n","      posts = mydoc.getElementsByTagName('TEXT')\n","      \n","      file = subjectname + \"-post_sentiments.csv\"\n","      with open(file, mode='w') as csv_file:\n","        csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","        #Add the column headers\n","        csv_writer.writerow(['Post', 'Sentiment'])\n","        for p in posts:\n","          post = p.firstChild.data\n","          if post != \"  \":\n","            csv_writer.writerow([post, scorer.score_sentence(post)])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jMjdtlshgsAL"},"source":["#example running calc_sentiment\n","calc_sentiment(distil_vader_avg_scorer)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R30f0ctGmW0i"},"source":["# **Predicting the BDI Answers**"]},{"cell_type":"markdown","metadata":{"id":"bWqPZQs3UxQj"},"source":["Predicts all of the answers to the BDI, for each subject.\n","\n","\n","*   scorer_name (*string*): name of scorer to name file\n","\n"]},{"cell_type":"code","metadata":{"id":"kzUBPHB9WtPO"},"source":["def predict_answers(scorer_name):\n","\n","  #create dataframe containing sentiment score for each answer in BDI\n","  csv_name = scorer_name + '/BDI_sentiment.csv'\n","  answer_scores = pd.read_csv(csv_name)\n","\n","  #loop through all subject xml files\n","  folder_path = '/content/drive/MyDrive/CS408/2019_2020_TEST_DATA/'\n","  for subject in subjects:\n","\n","    #create csv per subject for their predicted and real answers \n","    createfile = subject + \"_predicted_answers-\" + scorer_name + \".csv\"\n","    with open(createfile, mode='w') as csv_file:\n","      csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n","      #Add the column headers\n","      csv_writer.writerow(['Question', 'Predicted Answer', 'Real Answer'])\n","\n","      #gather all sentiment scores for a single user's postings\n","      readfile = subject + \"-post_sentiments.csv\"\n","      temp_df = pd.read_csv(readfile)\n","      sentiment_posts = []\n","      for i, row in temp_df.iterrows():\n","        sentiment_posts.append(row['Sentiment'])\n","\n","      index = 1\n","      #Search 2019/2020 txt files for subjectname\n","      for txtname in glob.glob(os.path.join(folder_path, '*.txt')):\n","        with open(txtname, 'r') as txt:\n","          for line in txt:\n","            values = line.split()\n","            if (values[0] == subject):\n","              for i, row in answer_scores:\n","                csv_writer.writerow([\"Q\" + str(index), compare_sentiments(row.Sentiment, sentiment_posts), values[index]])\n","                index += 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_mT-27wcBHAO"},"source":["**Compares the sentiment intensity scores between the answers of a question in BDI and a users postings.**\n","- answer_scores (*list*): list of the sentiment scores per answer statemnt to a question\n","- post_scores (*list*): list of the sentiment scores for all of a users postings"]},{"cell_type":"code","metadata":{"id":"I9sbgC9-Wmr0"},"source":["def compare_sentiments(answer_scores, post_scores):\n","  #creates list with the values (sentiment scores) from dict \n","  answer_scores_list = [*answer_scores.values()]\n","\n","  #countlist will store how many times an answer has been picked\n","  # index of list = answer number\n","  if len(answer_scores_list) > 4:\n","    countlist = [0, 0, 0, 0, 0, 0, 0]\n","  else:\n","    countlist = [0, 0, 0, 0]\n","\n","  #goes through each post score and picks answer with closest score\n","  for post_score in post_scores:\n","    min_difference = min(answer_scores.values(), key=lambda x:abs(x-post_score))\n","    closest = answer_scores_list.index(min_difference)\n","    countlist[closest] += 1\n","\n","  #picks the answer by chosing the index with the highest count\n","  predicted = countlist.index(max(countlist))\n","\n","  #question with more than 4 answers, convert to incorporate letters\n","  if len(countlist) > 4:\n","    numDict = {0:'0', 1:'1a', 2: '1b', 3: '2a', 4: '2b', 5: '3a', 6: '3b'}\n","    predicted = numDict[predicted]\n","\n","  return predicted"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J2cCGakQranX"},"source":["# **Evaluation Metrics**\n","* **Average Hit Rate (AHR)** - calculates the HR (hit rate) averaged over all users, where the HR is how many questions the system has predicted correctly.\n","* **Average Closeness Rate (ACR)** - calculates how close the system has predicted answer values for every question, averaged over all users.\n","* **Average Difference between Overall Depression Levels (ADODL)** - calculates how close the system has predicted a subject's depression score compared to their real score, averaged over all users.\n","* **Depression Category Hit Rate (DCHR)** - calculates the percentage of cases where the automated question answers matched up to the subject's true depression category."]},{"cell_type":"markdown","metadata":{"id":"2hr1Wr0qu7Vz"},"source":["**Convert Answer Class to Respective Value**\n","\n","> Due to question 16 and question 18 having 7 possible answers (0, 1a, 1b, 2a, 2b, 3a, 3b), the answer values are either stored as strings or variables in the dataframes. When calculating depression scores, only the number is taken into consideration. Thus, the method convert_to_int will take in any answer class and return it as an integer (i.e convert_to_int('1a') returns 1 and convert_to_int(2) just returns 2).\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"MrGWqliusxPj"},"source":["#converts string to integer for the answer class\n","def convert_to_int(s):\n","  if type(s) == int:\n","    return s\n","  else:\n","    #if 1a - 3b then take only the number part of string\n","    s = s[0]\n","    integer = int(s)\n","    return integer"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iCghOqySu9ED"},"source":["### **Calculate AHR**"]},{"cell_type":"code","metadata":{"id":"D9LWwchl5oRS"},"source":["def calc_HR(subject, model):\n","  HR = 0\n","  temp_df = pd.read_csv(subject + \"-\" + model + \".csv\")\n","  for index, row in temp_df.iterrows(): \n","    if (row[\"Real Answer\"] == row[\"Predicted Answer\"]):\n","      HR += 1\n","  return HR"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G-m_0BEF5aw0"},"source":["def calc_AHR(model):\n","  #calculate HR for all users then divide by total number of users\n","  total_correct_guesses = 0\n","  for subject in subjects:\n","    total_correct_guesses += calc_HR(subject, model)\n","\n","  #1890 = 90 subjects * 21 questions\n","  AHR = (total_correct_guesses / 1890) * 100\n","  return AHR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aY2DKCfHvF_u"},"source":["### **Calculate ACR**"]},{"cell_type":"code","metadata":{"id":"0PczJV437In4"},"source":["def calc_CR(row):\n","  real_answer = convert_to_int(row[\"Real Answer\"])\n","  predicted_answer = convert_to_int(row[\"Predicted Answer\"])\n","\n","  #ad = absolute difference i.e. system = 3 and real = 1, so ad = 2\n","  ad = abs(predicted_answer - real_answer)\n","\n","  #cr = mad - ad / mad\n","  CR = (3-ad)/3\n","  return CR"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8S0nIXRL7QPh"},"source":["def calc_ACR(model):\n","  CR_total = 0\n","  for subject in subjects:\n","    temp_df = pd.read_csv(subject + \"-\" + model + \".csv\")\n","    for index, row in temp_df.iterrows():\n","      CR_total += calc_CR(row)\n","\n","  ACR = (CR_total/1890) * 100\n","  return ACR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JVVgM6gxvQto"},"source":["### **Calculate ADODL**"]},{"cell_type":"code","metadata":{"id":"o5CtZjb37SAT"},"source":["def calc_DODL(subject, model):\n","    temp_df = pd.read_csv(subject + \"-\" + model + \".csv\")\n","    real_category = 0\n","    predicted_category = 0\n","    #need to account for 1a/1b etc\n","    for index, row in temp_df.iterrows(): \n","      real_category += convert_to_int(row[\"Real Answer\"])\n","      predicted_category += convert_to_int(row[\"Predicted Answer\"])\n","\n","    overall_ad = abs(predicted_category - real_category)\n","    DODL = (63 - overall_ad) / 63\n","\n","    return DODL"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u2ZDN1qc7iae"},"source":["def calc_ADODL(model):\n","  total_DODLs = 0\n","  for subject in subjects:\n","    total_DODLs += calc_DODL(subject, model)\n","  ADODL = (total_DODLs / 90) * 100\n","\n","  return ADODL"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dB34-SnhvlBY"},"source":["### **Calculate DCHR**"]},{"cell_type":"code","metadata":{"id":"KTGJLDen7ktV"},"source":["'''\n","  0 - 9: minimal depression\n","  10 - 18: mild depression\n","  19 - 29: moderate depression\n","  30 - 63: severe depression\n","'''\n","def calc_DCHR(model):\n","  correct_guesses = 0\n","  for subject in subjects:\n","    real_category = 0\n","    predicted_category = 0\n","    temp_df = pd.read_csv(subject + \"-\" + model + \".csv\")\n","\n","    #need to account for 1a/1b etc\n","    for index, row in temp_df.iterrows(): \n","      real_category += convert_to_int(row[\"Real Answer\"])\n","      predicted_category += convert_to_int(row[\"Predicted Answer\"])\n","\n","    if (0 <= real_category <= 9) & (0 <= predicted_category <= 9):\n","      correct_guesses += 1\n","    elif (10 <= real_category <= 18) & (10 <= predicted_category <= 18):\n","      correct_guesses += 1\n","    elif (19 <= real_category <= 29) & (19 <= predicted_category <= 29):\n","      correct_guesses += 1\n","    elif (30 <= real_category <= 63) & (30 <= predicted_category <= 63):\n","      correct_guesses += 1\n","    \n","  DCHR = (correct_guesses / 90) * 100\n","  return DCHR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K8D-p2VLrlbC"},"source":["# **Results of Models**"]},{"cell_type":"markdown","metadata":{"id":"msEZK8NeTnNW"},"source":["### **BERT Scorers**"]},{"cell_type":"markdown","metadata":{"id":"sj7rQorBUAkd"},"source":["**BERT Average Scorer**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WTseSN1sgABI","executionInfo":{"status":"ok","timestamp":1617751514504,"user_tz":-60,"elapsed":2421,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"b0bb5e58-9e5f-49cc-c24b-28d13b4a7052"},"source":["%cd bert_vader_avg_scorer\n","\n","#bert vader avg \n","print(\"AHR: \", calc_AHR('bert_vader_avg_scorer'))\n","print(\"ACR: \", calc_ACR('bert_vader_avg_scorer'))\n","print(\"ADODL: \", calc_ADODL('bert_vader_avg_scorer'))\n","print(\"DCHR: \", calc_DCHR('bert_vader_avg_scorer'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["AHR:  23.597883597883598\n","ACR:  65.4144620811287\n","ADODL:  76.56084656084651\n","DCHR:  18.88888888888889\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yUg0NwF4UDjF"},"source":["**BERT Max Scorer**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4lzDeQp97W5","executionInfo":{"status":"ok","timestamp":1617809622518,"user_tz":-60,"elapsed":2329,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"7272b693-bee0-44d8-ec84-1404152f94a1"},"source":["%cd bert_vader_max_scorer\n","\n","#bert vader max\n","print(\"AHR: \", calc_AHR('bert_vader_max_scorer'))\n","print(\"ACR: \", calc_ACR('bert_vader_max_scorer'))\n","print(\"ADODL: \", calc_ADODL('bert_vader_max_scorer'))\n","print(\"DCHR: \", calc_DCHR('bert_vader_max_scorer'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["AHR:  19.417989417989418\n","ACR:  60.77601410934738\n","ADODL:  73.43915343915339\n","DCHR:  23.333333333333332\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"d80-qgFzTzJG"},"source":["### **DistilBERT Scorer**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7yxQEdjRMUzB","executionInfo":{"status":"ok","timestamp":1629107342086,"user_tz":-60,"elapsed":33994,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"f18fb341-974c-4008-d7f0-1ecd736222b7"},"source":["%cd distil_vader_avg_scorer\n","\n","#distil avg\n","print(\"AHR: \", calc_AHR('distil_vader_avg_scorer'))\n","print(\"ACR: \", calc_ACR('distil_vader_avg_scorer'))\n","print(\"ADODL: \", calc_ADODL('distil_vader_avg_scorer'))\n","print(\"DCHR: \", calc_DCHR('distil_vader_avg_scorer'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/CS408/Sentiment_Analysis/distil_vader_avg_scorer\n","AHR:  24.55026455026455\n","ACR:  64.97354497354499\n","ADODL:  77.1781305114638\n","DCHR:  28.888888888888886\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7G8Ufpk_T5Mo"},"source":["### **RoBERTa Scorer**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qr4-sPQYHyNp","executionInfo":{"status":"ok","timestamp":1629107395379,"user_tz":-60,"elapsed":50282,"user":{"displayName":"Erin Macfarlane","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj0_xwTZxkXsQUII-LehAPUB3M0y9Z6Xeb7Ef9CtQ=s64","userId":"04346088377799420888"}},"outputId":"d9f523ac-2366-48e8-a7df-834ef43f03a0"},"source":["%cd roberta_vader_avg_scorer\n","\n","#roberta avg\n","print(\"AHR: \", calc_AHR('roberta_vader_avg_scorer'))\n","print(\"ACR: \", calc_ACR('roberta_vader_avg_scorer'))\n","print(\"ADODL: \", calc_ADODL('roberta_vader_avg_scorer'))\n","print(\"DCHR: \", calc_DCHR('roberta_vader_avg_scorer'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/CS408/Sentiment_Analysis/roberta_vader_avg_scorer\n","AHR:  23.597883597883598\n","ACR:  65.4144620811287\n","ADODL:  76.56084656084651\n","DCHR:  18.88888888888889\n"],"name":"stdout"}]}]}